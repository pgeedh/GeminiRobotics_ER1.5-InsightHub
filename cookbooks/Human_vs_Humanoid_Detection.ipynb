{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ü§ñ Distinguishing Humans from Humanoids (Photo & Video)\n",
                "\n",
                "This cookbook demonstrates how to use Gemini 1.5 Pro's **multimodal capabilities** to distinguish between biological humans and humanoid robots. \n",
                "\n",
                "We will visualize the **Before** (Raw Input) and **After** (Safety Annotation) states."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Setup & API Key\n",
                "# Using %pip as recommended to avoid environment issues\n",
                "%pip install -q -U google-genai pillow matplotlib python-dotenv\n",
                "\n",
                "from google import genai\n",
                "from google.genai import types\n",
                "import os\n",
                "import json\n",
                "import re\n",
                "import PIL.Image\n",
                "import PIL.ImageDraw\n",
                "import PIL.ImageFont\n",
                "from IPython.display import display, Markdown\n",
                "from dotenv import load_dotenv\n",
                "\n",
                "# Load API Key from .env file\n",
                "load_dotenv()\n",
                "api_key = os.getenv(\"GEMINI_API_KEY\")\n",
                "\n",
                "if not api_key:\n",
                "    print(\"‚ùå Error: GEMINI_API_KEY not found in .env file.\")\n",
                "else:\n",
                "    client = genai.Client(api_key=api_key)\n",
                "    print(\"‚úÖ Client initialized with gemini-robotics-er-1.5-preview.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üì∏ Part 1: Image Analysis (Visualization)\n",
                "\n",
                "We will prompt the model to return bounding boxes, then draw them to show the \"After\" state."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def extract_json(text):\n",
                "    # Helper to clean markdown code blocks from response\n",
                "    match = re.search(r'```json\\s*(.*?)\\s*```', text, re.DOTALL)\n",
                "    if match:\n",
                "        return match.group(1)\n",
                "    return text\n",
                "\n",
                "def analyze_and_visualize(image_path):\n",
                "    if not os.path.exists(image_path):\n",
                "        print(f\"‚ùå Error: {image_path} not found.\")\n",
                "        return\n",
                "\n",
                "    print(\"üñºÔ∏è BEFORE: Raw Input Image\")\n",
                "    img = PIL.Image.open(image_path)\n",
                "    display(img)\n",
                "    \n",
                "    # Convert to bytes for new API\n",
                "    with open(image_path, 'rb') as f:\n",
                "        image_bytes = f.read()\n",
                "\n",
                "    # --- GEMINI ROBOTICS CALL ---\n",
                "    print(\"üß† Analyzing with Gemini Robotics ER 1.5...\")\n",
                "    \n",
                "    prompt = \"\"\"\n",
                "    Analyze this scene for safety classification. \n",
                "    \n",
                "    1. DETECT all bipedal figures in the image.\n",
                "    2. For each figure, CLASSIFY as either 'HUMAN' or 'HUMANOID_ROBOT'.\n",
                "    3. Return bounding boxes as a JSON array with labels.\n",
                "    \n",
                "    Output format: \n",
                "    [{\"box_2d\": [ymin, xmin, ymax, xmax], \"label\": \"HUMAN (confidence)\"}, ...]\n",
                "    normalized to 0-1000.\n",
                "    \"\"\"\n",
                "    \n",
                "    try:\n",
                "        response = client.models.generate_content(\n",
                "            model=\"gemini-robotics-er-1.5-preview\",\n",
                "            contents=[\n",
                "                types.Part.from_bytes(\n",
                "                    data=image_bytes,\n",
                "                    mime_type='image/jpeg',\n",
                "                ),\n",
                "                prompt\n",
                "            ],\n",
                "            config=types.GenerateContentConfig(\n",
                "                temperature=0.5,\n",
                "                thinking_config=types.ThinkingConfig(thinking_budget=1024) # Enable thinking for reasoning\n",
                "            )\n",
                "        )\n",
                "    except Exception as e:\n",
                "        print(f\"‚ùå API Error: {e}\")\n",
                "        return\n",
                "    \n",
                "    # --- PARSE & DRAW ---\n",
                "    try:\n",
                "        text_output = response.text\n",
                "        print(text_output) # Debug output\n",
                "        \n",
                "        data = json.loads(extract_json(text_output))\n",
                "        draw = PIL.ImageDraw.Draw(img)\n",
                "        width, height = img.size\n",
                "        \n",
                "        for item in data:\n",
                "            box = item.get('box_2d')\n",
                "            label = item.get('label')\n",
                "            if not box: continue\n",
                "            \n",
                "            # Un-normalize coordinates\n",
                "            ymin, xmin, ymax, xmax = box\n",
                "            xmin = int(xmin / 1000 * width)\n",
                "            xmax = int(xmax / 1000 * width)\n",
                "            ymin = int(ymin / 1000 * height)\n",
                "            ymax = int(ymax / 1000 * height)\n",
                "            \n",
                "            color = \"red\" if \"HUMAN\" in label.upper() else \"green\"\n",
                "            \n",
                "            draw.rectangle([xmin, ymin, xmax, ymax], outline=color, width=4)\n",
                "            draw.text((xmin, ymin-15), label, fill=color)\n",
                "            \n",
                "        print(\"\\nüéØ AFTER: Annotated Safety View\")\n",
                "        display(img)\n",
                "        \n",
                "    except Exception as e:\n",
                "        print(f\"‚ö†Ô∏è Could not visualize: {e}\")\n",
                "        print(response.text)\n",
                "\n",
                "# RUN VISUALIZATION\n",
                "image_path = \"../assets/test1.jpg\"\n",
                "analyze_and_visualize(image_path)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}