{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ü§ñ Distinguishing Humans from Humanoids (Photo & Video)\n",
                "\n",
                "This cookbook demonstrates how to use Gemini 1.5 Pro's **multimodal capabilities** to distinguish between biological humans and humanoid robots in both **static images** and **video feeds**.\n",
                "\n",
                "**Key Capabilities Covered:**\n",
                "1.  **Spatial Reasoning (Images)**: Bounding box detection of humans vs robots.\n",
                "2.  **Temporal Reasoning (Video)**: Analyzing movement patterns (gait, fluidity) to distinguish biological motion from servo-driven motion."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Setup & API Key\n",
                "!pip install -q -U google-generativeai pillow\n",
                "\n",
                "import google.generativeai as genai\n",
                "import os\n",
                "import time\n",
                "import PIL.Image\n",
                "from IPython.display import display, Image, Markdown\n",
                "\n",
                "# üîë ENTER YOUR API KEY HERE\n",
                "# Get one at https://aistudio.google.com/\n",
                "os.environ[\"GEMINI_API_KEY\"] = \"YOUR_API_KEY_HERE\" \n",
                "genai.configure(api_key=os.environ[\"GEMINI_API_KEY\"])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üì∏ Part 1: Image Analysis\n",
                "We use a specialized prompt to detect fine-grained visual cues (skin texture vs cabling)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def analyze_image(image_path):\n",
                "    print(f\"üîç Analyzing Image: {image_path}...\")\n",
                "    model = genai.GenerativeModel('gemini-1.5-pro-latest')\n",
                "    \n",
                "    prompt = \"\"\"\n",
                "    Analyze this scene for safety classification. \n",
                "    \n",
                "    1. DETECT all bipedal figures in the image.\n",
                "    2. For each figure, CLASSIFY as either 'HUMAN' or 'HUMANOID_ROBOT'.\n",
                "    3. PROVIDE EVIDENCE for your classification based on visual features:\n",
                "       - Human Cues: Skin texture/subsurface scattering, breathing motion, flexible clothing folds, hair, imperfect posture.\n",
                "       - Robot Cues: Exposed cabling, rigid joint segments, metallic/plastic sheen, LED indicators, rigid gait, perfect symmetry.\n",
                "       \n",
                "    Output format: JSON list of objects { \"box_2d\": [y,x,y,x], \"type\": \"HUMAN\" | \"HUMANOID\", \"confidence\": 0-1, \"evidence\": \"...\" }\n",
                "    \"\"\"\n",
                "    \n",
                "    if not os.path.exists(image_path):\n",
                "        return \"‚ùå Error: Image file not found. Please add it to the assets folder.\"\n",
                "\n",
                "    img = PIL.Image.open(image_path)\n",
                "    response = model.generate_content([prompt, img])\n",
                "    return response.text\n",
                "\n",
                "# RUN IMAGE ANALYSIS\n",
                "# Ensure you have added 'human_vs_robot.jpg' to the '../assets/' folder\n",
                "image_path = \"../assets/human_vs_robot.jpg\"\n",
                "print(analyze_image(image_path))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üé• Part 2: Video Analysis (Temporal Gait Analysis)\n",
                "For video, we upload the file to Gemini's context cache. This allows the model to watch the **movement** quality (fluid vs rigid) which is often the best differentiator."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def analyze_video(video_path):\n",
                "    print(f\"üé¨ Uploading Video: {video_path}...\")\n",
                "    \n",
                "    if not os.path.exists(video_path):\n",
                "        return \"‚ùå Error: Video file not found. Please add it to the assets folder.\"\n",
                "\n",
                "    # 1. Upload Video\n",
                "    video_file = genai.upload_file(path=video_path)\n",
                "    \n",
                "    # 2. Wait for Processing\n",
                "    while video_file.state.name == \"PROCESSING\":\n",
                "        print(\".\", end=\"\")\n",
                "        time.sleep(1)\n",
                "        video_file = genai.get_file(video_file.name)\n",
                "        \n",
                "    if video_file.state.name == \"FAILED\":\n",
                "        return \"‚ùå Video processing failed.\"\n",
                "\n",
                "    print(\"\\n‚úÖ Video Ready. Asking Gemini...\")\n",
                "    \n",
                "    # 3. Temporal Prompt\n",
                "    model = genai.GenerativeModel('gemini-1.5-pro-latest')\n",
                "    prompt = \"\"\"\n",
                "    Watch this video carefully. Distinguish between BIOLOGICAL HUMANS and HUMANOID ROBOTS based on movement dynamics.\n",
                "    \n",
                "    task:\n",
                "    1. Identify the timestamps where a figure enters the frame.\n",
                "    2. Analyze the gait (walking cycle):\n",
                "       - Human: Fluid weight transfer, heel-strike, hip rotation, arm swing variance.\n",
                "       - Robot: ZMP (Zero Moment Point) walking, bent-knee 'groucho' walk, rigid torso, mechanical servo noise (if audio exists).\n",
                "    \n",
                "    RETURN a classification report for each figure tracked.\n",
                "    \"\"\"\n",
                "    \n",
                "    response = model.generate_content([video_file, prompt])\n",
                "    return response.text\n",
                "\n",
                "# RUN VIDEO ANALYSIS\n",
                "# Ensure you have added 'human_vs_robot.mp4' to the '../assets/' folder\n",
                "video_path = \"../assets/human_vs_robot.mp4\"\n",
                "print(analyze_video(video_path))"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}