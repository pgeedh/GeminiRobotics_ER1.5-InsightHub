{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ü§ñ Distinguishing Humans from Humanoids (Photo & Video)\n",
                "\n",
                "This cookbook demonstrates how to use Gemini 1.5 Pro's **multimodal capabilities** to distinguish between biological humans and humanoid robots. \n",
                "\n",
                "We will visualize the **Before** (Raw Input) and **After** (Safety Annotation) states."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Setup & API Key\n",
                "!pip install -q -U google-generativeai pillow matplotlib\n",
                "\n",
                "import google.generativeai as genai\n",
                "import os\n",
                "import json\n",
                "import re\n",
                "import PIL.Image\n",
                "import PIL.ImageDraw\n",
                "import PIL.ImageFont\n",
                "from IPython.display import display, Markdown\n",
                "\n",
                "# üîë ENTER YOUR API KEY HERE\n",
                "os.environ[\"GEMINI_API_KEY\"] = \"YOUR_API_KEY_HERE\" \n",
                "genai.configure(api_key=os.environ[\"GEMINI_API_KEY\"])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üì∏ Part 1: Image Analysis (Visualization)\n",
                "\n",
                "We will prompt the model to return bounding boxes, then draw them to show the \"After\" state."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def extract_json(text):\n",
                "    # Helper to clean markdown code blocks from response\n",
                "    match = re.search(r'```json\\s*(.*?)\\s*```', text, re.DOTALL)\n",
                "    if match:\n",
                "        return match.group(1)\n",
                "    return text\n",
                "\n",
                "def analyze_and_visualize(image_path):\n",
                "    if not os.path.exists(image_path):\n",
                "        print(f\"‚ùå Error: {image_path} not found.\")\n",
                "        return\n",
                "\n",
                "    print(\"üñºÔ∏è BEFORE: Raw Input Image\")\n",
                "    img = PIL.Image.open(image_path)\n",
                "    display(img)\n",
                "\n",
                "    # --- GEMINI CALL ---\n",
                "    print(\"üß† Analyzing...\")\n",
                "    model = genai.GenerativeModel('models/gemini-1.5-pro-latest')\n",
                "    \n",
                "    prompt = \"\"\"\n",
                "    Analyze this scene for safety classification. \n",
                "    \n",
                "    1. DETECT all bipedal figures in the image.\n",
                "    2. For each figure, CLASSIFY as either 'HUMAN' or 'HUMANOID_ROBOT'.\n",
                "    3. Return 2D Bounding Boxes [ymin, xmin, ymax, xmax] normalized 0-1000.\n",
                "       \n",
                "    Output format: JSON list of objects \n",
                "    [ \n",
                "      { \"box_2d\": [y,x,y,x], \"type\": \"HUMAN\", \"confidence\": 0.99 },\n",
                "      { \"box_2d\": [y,x,y,x], \"type\": \"HUMANOID_ROBOT\", \"confidence\": 0.99 }\n",
                "    ]\n",
                "    \"\"\"\n",
                "    \n",
                "    response = model.generate_content([prompt, img])\n",
                "    \n",
                "    # --- PARSE & DRAW ---\n",
                "    try:\n",
                "        data = json.loads(extract_json(response.text))\n",
                "        draw = PIL.ImageDraw.Draw(img)\n",
                "        width, height = img.size\n",
                "        \n",
                "        for item in data:\n",
                "            box = item['box_2d']\n",
                "            label = item['type']\n",
                "            \n",
                "            # Un-normalize coordinates\n",
                "            ymin, xmin, ymax, xmax = box\n",
                "            xmin = int(xmin / 1000 * width)\n",
                "            xmax = int(xmax / 1000 * width)\n",
                "            ymin = int(ymin / 1000 * height)\n",
                "            ymax = int(ymax / 1000 * height)\n",
                "            \n",
                "            # Color Logic: Red = Human (Caution), Green = Robot (Safe)\n",
                "            color = \"red\" if \"HUMAN\" in label.upper() else \"green\"\n",
                "            \n",
                "            draw.rectangle([xmin, ymin, xmax, ymax], outline=color, width=4)\n",
                "            draw.text((xmin, ymin-15), label, fill=color)\n",
                "            \n",
                "        print(\"\\nüéØ AFTER: Annotated Safety View\")\n",
                "        display(img)\n",
                "        \n",
                "    except Exception as e:\n",
                "        print(f\"‚ö†Ô∏è Could not visualize (Raw output below): {e}\")\n",
                "        print(response.text)\n",
                "\n",
                "# RUN VISUALIZATION\n",
                "image_path = \"../assets/test1.jpg\"\n",
                "analyze_and_visualize(image_path)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}